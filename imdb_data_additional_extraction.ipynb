{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f21ddfe9",
   "metadata": {},
   "source": [
    "Jamison Hunter\n",
    "\n",
    "July 21, 2023\n",
    "\n",
    "# IMDB Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebb07d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tmdbsimple as tmdb\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1298e133",
   "metadata": {},
   "source": [
    "# Retrieving Additional Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bee343f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_with_rating(movie_id):\n",
    "    \"\"\"Copied from Coding Dojo Learning Platform\"\"\"\n",
    "    # Get the movie object for the current id\n",
    "    movie = tmdb.Movies(movie_id)\n",
    "    # save the .info .releases dictionaries\n",
    "    info = movie.info()\n",
    "    releases = movie.releases()\n",
    "    # Loop through countries in releases\n",
    "    for c in releases['countries']:\n",
    "        # if the country abbreviation==US\n",
    "        if c['iso_3166_1' ] =='US':\n",
    "            ## save a \"certification\" key in the info dict with the certification\n",
    "            info['certification'] = c['certification']\n",
    "    \n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbcd61b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json(new_data, filename): \n",
    "    \"\"\"Appends a list of records (new_data) to a json file (filename). \n",
    "    Adapted from: https://www.geeksforgeeks.org/append-to-json-file-using-python/\"\"\"  \n",
    "    \n",
    "    with open(filename,'r+') as file:\n",
    "        # First we load existing data into a dict.\n",
    "        file_data = json.load(file)\n",
    "        ## Choose extend or append\n",
    "        if (type(new_data) == list) & (type(file_data) == list):\n",
    "            file_data.extend(new_data)\n",
    "        else:\n",
    "             file_data.append(new_data)\n",
    "        # Sets file's current position at offset.\n",
    "        file.seek(0)\n",
    "        # convert back to json.\n",
    "        json.dump(file_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28398246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['api-token', 'api-key'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('/Users/Jamison/.secret/tmdb_api.json', 'r') as f:\n",
    "    login = json.load(f)\n",
    "# displaying json dictionary keys for the TMDB API\n",
    "login.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abf5fdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmdb.API_KEY =  login['api-key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1d123e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'Data',\n",
       " 'final_results_indianapolis_pizza.csv.gz',\n",
       " 'final_tmdb_data_2000.csv.gz',\n",
       " 'final_tmdb_data_2001.csv.gz',\n",
       " 'hero_information.csv',\n",
       " 'results_in_progress_indianapolis_pizza.json',\n",
       " 'title_akas.csv.gz',\n",
       " 'title_basics.csv.gz',\n",
       " 'title_ratings.csv.gz',\n",
       " 'tmdb_api_results_2000.json',\n",
       " 'tmdb_api_results_2001.json',\n",
       " 'tmdb_results_combined.csv.gz']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# referencing previous Data folder\n",
    "FOLDER = \"Data/\"\n",
    "os.makedirs(FOLDER, exist_ok=True)\n",
    "os.listdir(FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8883aa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the dataframe from project part 1 as basics:\n",
    "basics = pd.read_csv(\"Data/title_basics.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d7e8e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jamison\\AppData\\Local\\Temp\\ipykernel_18364\\3498641292.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for YEAR in tqdm_notebook(YEARS_TO_GET, desc='YEARS', position=0):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17159de1d5a4485fa1c479807f9a0e34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "YEARS:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jamison\\AppData\\Local\\Temp\\ipykernel_18364\\3498641292.py:31: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for movie_id in tqdm_notebook(movie_ids_to_get,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec233eafecb643cea409422670bf4700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Movies from 2002:   0%|          | 0/1570 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jamison\\AppData\\Local\\Temp\\ipykernel_18364\\3498641292.py:31: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for movie_id in tqdm_notebook(movie_ids_to_get,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "765c899673e14b9c808aeb7fd5a8f000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Movies from 2003:   0%|          | 0/1685 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jamison\\AppData\\Local\\Temp\\ipykernel_18364\\3498641292.py:31: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for movie_id in tqdm_notebook(movie_ids_to_get,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae7dbdc950624d83b43019bc31c580a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Movies from 2004:   0%|          | 0/1902 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jamison\\AppData\\Local\\Temp\\ipykernel_18364\\3498641292.py:31: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for movie_id in tqdm_notebook(movie_ids_to_get,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90b5d045fdc341e0aeb66ab15204905a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Movies from 2005:   0%|          | 0/2184 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jamison\\AppData\\Local\\Temp\\ipykernel_18364\\3498641292.py:31: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for movie_id in tqdm_notebook(movie_ids_to_get,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46fb22f2c1394f2c998adbd9c920cf0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Movies from 2006:   0%|          | 0/2438 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jamison\\AppData\\Local\\Temp\\ipykernel_18364\\3498641292.py:31: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for movie_id in tqdm_notebook(movie_ids_to_get,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e261833bfaf14269b592203b7da4eab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Movies from 2007:   0%|          | 0/2576 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Total errors: 2746\n"
     ]
    }
   ],
   "source": [
    "YEARS_TO_GET = [2002, 2003, 2004, 2005, 2006, 2007]\n",
    "errors = [ ]\n",
    "# Start of OUTER loop\n",
    "for YEAR in tqdm_notebook(YEARS_TO_GET, desc='YEARS', position=0):\n",
    "\n",
    "    #Defining the JSON file to store results for year\n",
    "    JSON_FILE = f'{FOLDER}tmdb_api_results_{YEAR}.json'\n",
    "\n",
    "    # Check if file exists\n",
    "    file_exists = os.path.isfile(JSON_FILE)\n",
    "\n",
    "    # If it does not exist: create it\n",
    "    if file_exists == False:\n",
    "    # save an empty dict with just \"imdb_id\" to the new json file.\n",
    "        with open(JSON_FILE,'w') as f:\n",
    "            json.dump([{'imdb_id':0}],f)\n",
    "\n",
    "    #Saving new year as the current df\n",
    "    df = basics.loc[ basics['startYear']==YEAR].copy()\n",
    "    # saving movie ids to list\n",
    "    movie_ids = df['tconst'].copy()\n",
    "\n",
    "    # Load existing data from json into a dataframe called \"previous_df\"\n",
    "    previous_df = pd.read_json(JSON_FILE)\n",
    "\n",
    "    # filter out any ids that are already in the JSON_FILE\n",
    "    movie_ids_to_get = movie_ids[~movie_ids.isin(previous_df['imdb_id'])]\n",
    "\n",
    "    #Get index and movie id from list\n",
    "    # INNER Loop\n",
    "    for movie_id in tqdm_notebook(movie_ids_to_get,\n",
    "                                  desc=f'Movies from {YEAR}',\n",
    "                                  position=1,\n",
    "                                  leave=True):\n",
    "        try:\n",
    "            # Retrieve then data for the movie id\n",
    "            temp = get_movie_with_rating(movie_id)  \n",
    "            # Append/extend results to existing file using a pre-made function\n",
    "            write_json(temp,JSON_FILE)\n",
    "            # Short 20 ms sleep to prevent overwhelming server\n",
    "            time.sleep(0.02)\n",
    "            \n",
    "        except Exception as e:\n",
    "            errors.append([movie_id, e])\n",
    "\n",
    "    final_year_df = pd.read_json(JSON_FILE)\n",
    "    final_year_df.to_csv(f\"{FOLDER}final_tmdb_data_{YEAR}.csv.gz\", compression=\"gzip\", index=False)\n",
    "\n",
    "print(f\"- Total errors: {len(errors)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de32fa8e",
   "metadata": {},
   "source": [
    "I have now acquired additional years worth of data, totalling from 2000 to 2007. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
